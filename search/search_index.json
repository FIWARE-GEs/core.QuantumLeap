{
    "docs": [
        {
            "location": "/",
            "text": "QuantumLeap\n\n\nQuantumLeap is an API that supports the storage of NGSI \nFIWARE NGSIv2\n data into a \ntime series database\n.\n\n\nIn the end, its goals are similar to those of \nFIWARE's Comet STH\n. However, Comet does not yet support NGSIv2, it's tied to MongoDB, and some of the conditions and constraints under which it was developed are no longer hold. That being said, there is nothing wrong with it; this is just an exploration on a new way to provide historical data for FIWARE NGSIv2 with different timeseries databases as backend.\n\n\nThe idea is to keep the translator phase swapable so as to look forward to having support for different timeseries databases. We started testing \nInfluxDB\n, \nRethinkDB\n and \nCrate\n. However, we have decided for now to focus on the NGSIv2-CrateDB translator because we find in \nCrate\n the following advantages:\n\n\n\n\nEasy scalability with containerized database cluster out of the box\n\n\nGeo-queries support out of the box\n\n\nNice SQL-like querying language to work with\n\n\nSupported integration with visualization tools like \nGrafana\n\n\n\n\nTypical Usage and How it works\n\n\nThe typical usage scenario for QuantumLeap would be the following:\n\n\n\n\nThe idea of \nQuantumLeap\n is pretty straightforward. By leveraging on the \nnotifications mechanism\n, clients instruct Orion \n(1)\n to notify QuantumLeap of the changes in the entities they care about. Details of this process are explained in the \nOrion Subscription part of the User Manual\n.\n\n\nThere is typically a whole \nIoT layer\n governed by 1 or more \nIoT Agents\n pushing data in NGSI format to the \nOrion Context Broker\n \n(2)\n.\n\n\nNotifications will arrive to QuantumLeap's API \n/v2/notify\n endpoint \n(3)\n. Its \nReporter\n submodule will parse and validate the notification and eventually feed it to the configured \nTranslator\n. The Translator is ultimately the responsible for persisting the NGSI information to the configured times-series database cluster.\n\n\nIn addition to the \n/v2/notify\n endpoint, the API is planned to include NGSI endpoints for advanced raw and aggregated data retrieval \n(4)\n for clients to query historical data.\n\n\nFor the visualisation of data \n(5)\n at the time being we are experimenting with \nGrafana\n complemented with open source plugins for the databases. In the future, we could envision a plugin for direct interaction with the \nquery\n API.\n\n\nMore information\n\n\n\n\nRefer to the \nAdmin Guide\n for info on how to install QuantumLeap and get it running.\n\n\nRefer to the \nUser Manual\n for more info on how to use it.",
            "title": "Home"
        },
        {
            "location": "/#quantumleap",
            "text": "QuantumLeap is an API that supports the storage of NGSI  FIWARE NGSIv2  data into a  time series database .  In the end, its goals are similar to those of  FIWARE's Comet STH . However, Comet does not yet support NGSIv2, it's tied to MongoDB, and some of the conditions and constraints under which it was developed are no longer hold. That being said, there is nothing wrong with it; this is just an exploration on a new way to provide historical data for FIWARE NGSIv2 with different timeseries databases as backend.  The idea is to keep the translator phase swapable so as to look forward to having support for different timeseries databases. We started testing  InfluxDB ,  RethinkDB  and  Crate . However, we have decided for now to focus on the NGSIv2-CrateDB translator because we find in  Crate  the following advantages:   Easy scalability with containerized database cluster out of the box  Geo-queries support out of the box  Nice SQL-like querying language to work with  Supported integration with visualization tools like  Grafana",
            "title": "QuantumLeap"
        },
        {
            "location": "/#typical-usage-and-how-it-works",
            "text": "The typical usage scenario for QuantumLeap would be the following:   The idea of  QuantumLeap  is pretty straightforward. By leveraging on the  notifications mechanism , clients instruct Orion  (1)  to notify QuantumLeap of the changes in the entities they care about. Details of this process are explained in the  Orion Subscription part of the User Manual .  There is typically a whole  IoT layer  governed by 1 or more  IoT Agents  pushing data in NGSI format to the  Orion Context Broker   (2) .  Notifications will arrive to QuantumLeap's API  /v2/notify  endpoint  (3) . Its  Reporter  submodule will parse and validate the notification and eventually feed it to the configured  Translator . The Translator is ultimately the responsible for persisting the NGSI information to the configured times-series database cluster.  In addition to the  /v2/notify  endpoint, the API is planned to include NGSI endpoints for advanced raw and aggregated data retrieval  (4)  for clients to query historical data.  For the visualisation of data  (5)  at the time being we are experimenting with  Grafana  complemented with open source plugins for the databases. In the future, we could envision a plugin for direct interaction with the  query  API.",
            "title": "Typical Usage and How it works"
        },
        {
            "location": "/#more-information",
            "text": "Refer to the  Admin Guide  for info on how to install QuantumLeap and get it running.  Refer to the  User Manual  for more info on how to use it.",
            "title": "More information"
        },
        {
            "location": "/user/",
            "text": "Usage Overview\n\n\nFirst you need to have QuantumLeap runnning (of course). Refer to the\n\nInstallation Manual\n for instructions.\n\n\nThen, you need to connect Orion Context Broker to QuantumLeap through a\nsubscription for each Entity Type whose historical data you are interested in.\nHistorical data for each entity type will be persisted as long as the\nsubscription is active.\n\n\nThe flow is therefore the following\n\n\n\n\nCreate an Orion subscription for each entity type of your interest once\n\n\nInsert and update your data to Orion as usual\n\n\nDone, your historical data will be persisted in QuantumLeap's database.\n\n\n\n\nLet's have a look in more detail of each step.\n\n\nOrion Subscription\n\n\nAs stated before, the link between Orion and QuantumLeap is established through\na subscription you need to create. It is therefore important that you understand\n well how the NGSIv2 Subscription mechanism works. This is carefully explained\nin the corresponding section of \nOrion docs\n.\n\n\nHere's an example of the payload of the subscription you need to create in Orion\n to establish the link Orion-QuantumLeap.\n\n\n{\n    \"description\": \"Test subscription\",\n    \"subject\": {\n        \"entities\": [\n        {\n            \"idPattern\": \".*\",\n            \"type\": \"Room\"\n        }\n        ],\n        \"condition\": {\n            \"attrs\": [\n            \"temperature\"\n            ]\n        }\n    },\n    \"notification\": {\n        \"http\": {\n            \"url\": \"http://quantumleap:8668/v2/notify\"\n        },\n        \"attrs\": [\n        \"temperature\"\n        ],\n        \"metadata\": [\"dateCreated\", \"dateModified\"]\n    },\n    \"throttling\": 5\n}\n\n\n\nImportant things to notice from the example.\n\n\n\n\n\n\nYou can create any valid NGSI subscription for your entities.\n\n\n\n\n\n\nThough not compulsory, it is highly recommended to include the\n\n\"metadata\": [\"dateCreated\", \"dateModified\"]\n part in the \nnotification\n\npart of the subscription. This instructs Orion to include the modification time\nof the attributes in the notification. This timestamp will be used as the time\nindex in the database. If this is somehow missing, QuantumLeap will use its\ncurrent system time at which the notification arrived, which might not be\nexactly what you want.\n\n\n\n\n\n\nNotifications must come in complete \nNGSI JSON Entity Representation\n\n form. Other forms, such as the \nsimplified entity representation\n\n are not supported by QL because they lack information on attribute types,\n required by QL to make proper translations. This means, don't use options like\n \n\"attrsFormat\": \"keyValues\"\n\n\n\n\n\n\nThe \n\"url\"\n field of the subscription specifies where Orion will send the\nnotifications. I.e, this must be QuantumLeap's \n/v2/notify\n endpoint. By default,\nQuantumLeap listens at port \n8668\n.\n\n\n\n\n\n\nData Insertion\n\n\nNow you are ready to insert (or keep updating) your entities as you've always\ndone in Orion Context Broker. Refer to the \ndocs\n\n for more instructions.\n\n\nIt's not a problem if the first insert was done before you created the\nsubscription. Of course, you will get historical records of the updates\nhappening after the subscription was created.\n\n\nHere's an example of an insert payload that will generate a notification based\non the subscription example shown before.\n\n\n{\n    \"id\": \"Room1\",\n    \"type\": \"Room\",\n    \"temperature\": {\n        \"value\": 24.2,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    },\n    \"pressure\": {\n        \"value\": 720,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    }\n}\n\n\n\nAttributes DataType Translation\n\n\nNGSI Attribute types typically used can be seen in the \nSpecification\n section\nof the \nNGSI API\n.\nThe table below shows which attribute types will be translated to which\n\nCrate Data Types\n.\n\n\n\n\n\n\n\n\nNGSI Type\n\n\nCrate Type\n\n\nObservation\n\n\n\n\n\n\n\n\n\n\nArray\n\n\narray(string)\n\n\nTODO: Support arrays of other types.\n\n\n\n\n\n\nBoolean\n\n\nboolean\n\n\n-\n\n\n\n\n\n\nDateTime\n\n\ntimestamp\n\n\n-\n\n\n\n\n\n\nInteger\n\n\nlong\n\n\nTODO: Fix this inconsistency ASAP!\n\n\n\n\n\n\ngeo:point\n\n\ngeo_point\n\n\nAttention!\n NGSI uses \"lat, long\" order whereas Crate stores points in [long, lat] order.\n\n\n\n\n\n\ngeo:json\n\n\ngeo_shape\n\n\n-\n\n\n\n\n\n\nNumber\n\n\nfloat\n\n\n-\n\n\n\n\n\n\nText\n\n\nstring\n\n\nThis is the default type if the provided type is unknown.\n\n\n\n\n\n\nStructuredValue\n\n\nobject\n\n\n-\n\n\n\n\n\n\n\n\nIf the type of any of the received attributes is not present in the column\n\nNGSI Type\n of the previous table, the value of such attribute will be treated\ninternally as a string.\n\n\nNOTE: Attributes metadata are still not being persisted.\n\n\nData Retrieval\n\n\nThe QuantumLeap endpoints to retrieve data are still to be developed.\n\n\nHowever, you can already query the persisted data either directly interacting\nwith the Crate database, or through the use of Grafana. Further details are\nexplained in the \nCrate\n and \nGrafana\n\nsections, respectively.\n\n\nWhat you need to know in the mean time is that QuantumLeap will create one\ntable per each entity type. Table names are formed with the \"et\" prefix plus\nthe lowercase version of the entity type. I.e, if your entity type is\n\nAirQualityObserved\n, the corresponding table name will be\n\netairqualityobserved\n. All created tables for now belong to the default \"doc\"\nschema.\n\n\nRestrictions\n\n\n\n\nYou cannot have two entity types with the same name but different\ncapitalization. E.g: \nPreprocessor\n and \nProcessor\n. The same applies for\nattribute names of a given entity. I.e, attributes \nhotSpot\n and \nhotspot\n\nwill be treated as the same. These are rare corner-cases, but it is worth\nkeeping in mind this. Ultimately, the correct naming of types and attributes\nshould respect the naming guidelines explained\n\nhere\n.\n\n\n\n\nThe Time Index\n\n\nA fundamental index in the timeseries database is the time index. You may be\nwondering... where is it stored?\n\n\nQuantumLeap will persist the time index for each notification in a special\ncolumn called \ntime_index\n.  If you payed attention in the\n\nOrion Subscription\n section, you know at least which value is used as the time\nindex. This is, the \n\"dateModified\"\n value notified by Orion or, if you\nmissed that option in the subscription, the notification arrival time.\n\n\nIn the future, this could be more flexible and allow users to define any\nDatetime attribute to be used as the time index.",
            "title": "Introduction"
        },
        {
            "location": "/user/#usage-overview",
            "text": "First you need to have QuantumLeap runnning (of course). Refer to the Installation Manual  for instructions.  Then, you need to connect Orion Context Broker to QuantumLeap through a\nsubscription for each Entity Type whose historical data you are interested in.\nHistorical data for each entity type will be persisted as long as the\nsubscription is active.  The flow is therefore the following   Create an Orion subscription for each entity type of your interest once  Insert and update your data to Orion as usual  Done, your historical data will be persisted in QuantumLeap's database.   Let's have a look in more detail of each step.",
            "title": "Usage Overview"
        },
        {
            "location": "/user/#orion-subscription",
            "text": "As stated before, the link between Orion and QuantumLeap is established through\na subscription you need to create. It is therefore important that you understand\n well how the NGSIv2 Subscription mechanism works. This is carefully explained\nin the corresponding section of  Orion docs .  Here's an example of the payload of the subscription you need to create in Orion\n to establish the link Orion-QuantumLeap.  {\n    \"description\": \"Test subscription\",\n    \"subject\": {\n        \"entities\": [\n        {\n            \"idPattern\": \".*\",\n            \"type\": \"Room\"\n        }\n        ],\n        \"condition\": {\n            \"attrs\": [\n            \"temperature\"\n            ]\n        }\n    },\n    \"notification\": {\n        \"http\": {\n            \"url\": \"http://quantumleap:8668/v2/notify\"\n        },\n        \"attrs\": [\n        \"temperature\"\n        ],\n        \"metadata\": [\"dateCreated\", \"dateModified\"]\n    },\n    \"throttling\": 5\n}  Important things to notice from the example.    You can create any valid NGSI subscription for your entities.    Though not compulsory, it is highly recommended to include the \"metadata\": [\"dateCreated\", \"dateModified\"]  part in the  notification \npart of the subscription. This instructs Orion to include the modification time\nof the attributes in the notification. This timestamp will be used as the time\nindex in the database. If this is somehow missing, QuantumLeap will use its\ncurrent system time at which the notification arrived, which might not be\nexactly what you want.    Notifications must come in complete  NGSI JSON Entity Representation \n form. Other forms, such as the  simplified entity representation \n are not supported by QL because they lack information on attribute types,\n required by QL to make proper translations. This means, don't use options like\n  \"attrsFormat\": \"keyValues\"    The  \"url\"  field of the subscription specifies where Orion will send the\nnotifications. I.e, this must be QuantumLeap's  /v2/notify  endpoint. By default,\nQuantumLeap listens at port  8668 .",
            "title": "Orion Subscription"
        },
        {
            "location": "/user/#data-insertion",
            "text": "Now you are ready to insert (or keep updating) your entities as you've always\ndone in Orion Context Broker. Refer to the  docs \n for more instructions.  It's not a problem if the first insert was done before you created the\nsubscription. Of course, you will get historical records of the updates\nhappening after the subscription was created.  Here's an example of an insert payload that will generate a notification based\non the subscription example shown before.  {\n    \"id\": \"Room1\",\n    \"type\": \"Room\",\n    \"temperature\": {\n        \"value\": 24.2,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    },\n    \"pressure\": {\n        \"value\": 720,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    }\n}",
            "title": "Data Insertion"
        },
        {
            "location": "/user/#attributes-datatype-translation",
            "text": "NGSI Attribute types typically used can be seen in the  Specification  section\nof the  NGSI API .\nThe table below shows which attribute types will be translated to which Crate Data Types .     NGSI Type  Crate Type  Observation      Array  array(string)  TODO: Support arrays of other types.    Boolean  boolean  -    DateTime  timestamp  -    Integer  long  TODO: Fix this inconsistency ASAP!    geo:point  geo_point  Attention!  NGSI uses \"lat, long\" order whereas Crate stores points in [long, lat] order.    geo:json  geo_shape  -    Number  float  -    Text  string  This is the default type if the provided type is unknown.    StructuredValue  object  -     If the type of any of the received attributes is not present in the column NGSI Type  of the previous table, the value of such attribute will be treated\ninternally as a string.  NOTE: Attributes metadata are still not being persisted.",
            "title": "Attributes DataType Translation"
        },
        {
            "location": "/user/#data-retrieval",
            "text": "The QuantumLeap endpoints to retrieve data are still to be developed.  However, you can already query the persisted data either directly interacting\nwith the Crate database, or through the use of Grafana. Further details are\nexplained in the  Crate  and  Grafana \nsections, respectively.  What you need to know in the mean time is that QuantumLeap will create one\ntable per each entity type. Table names are formed with the \"et\" prefix plus\nthe lowercase version of the entity type. I.e, if your entity type is AirQualityObserved , the corresponding table name will be etairqualityobserved . All created tables for now belong to the default \"doc\"\nschema.",
            "title": "Data Retrieval"
        },
        {
            "location": "/user/#restrictions",
            "text": "You cannot have two entity types with the same name but different\ncapitalization. E.g:  Preprocessor  and  Processor . The same applies for\nattribute names of a given entity. I.e, attributes  hotSpot  and  hotspot \nwill be treated as the same. These are rare corner-cases, but it is worth\nkeeping in mind this. Ultimately, the correct naming of types and attributes\nshould respect the naming guidelines explained here .",
            "title": "Restrictions"
        },
        {
            "location": "/user/#the-time-index",
            "text": "A fundamental index in the timeseries database is the time index. You may be\nwondering... where is it stored?  QuantumLeap will persist the time index for each notification in a special\ncolumn called  time_index .  If you payed attention in the Orion Subscription  section, you know at least which value is used as the time\nindex. This is, the  \"dateModified\"  value notified by Orion or, if you\nmissed that option in the subscription, the notification arrival time.  In the future, this could be more flexible and allow users to define any\nDatetime attribute to be used as the time index.",
            "title": "The Time Index"
        },
        {
            "location": "/user/troubleshooting/",
            "text": "Troubleshooting\n\n\nSomething not working as expected? Don't worry! the expected thing is for it not to work :p.\n\n\nCheckout the following section to make sure you didn't miss a critical step, and if none of that applies to your case, then refer to the \nBug Reporting\n section.\n\n\nNothing Happens\n\n\nIf you don't see your data being saved in the database, before reporting a bug please ask yourself the following questions:\n\n\n\n\n\n\nHave you created a subscription for the entity type you are inserting?\n\n\n\n\n\n\nAre you inserting/updating attributes listed in the \"condition\" of the subscription? I.e, will Orion trigger notifications for that insert/update?\n\n\n\n\n\n\nIs the location of QuantumLeap expressed in the \nnotify_url\n field of the subscription a resolvable url for the conteinerized Orion? Review the \nUsage Section\n for more details.\n\n\n\n\n\n\nAre you running the different components behind firewalls? If so, did you open the corresponding ports? (See the \nPorts\n section.)\n\n\n\n\n\n\nBug reporting\n\n\nBugs should be reported in the form of \nissues\n in the github repository.\n\n\nPlease, look through the open issues before opening a repeated one :)\n\n\nInclude as much context info as possible, also ideally the following things:\n\n\n\n\n\n\nThe inserted entity that may have caused the problem. E.g:\n\n\n{\n    'id': 'Room1',\n    'type': 'Room',\n    'attr1': 'blabla',\n    ...\n}\n\n\n\n\n\n\n\nThe payload of the subscription(s) that you created.\n\n\n\n\n\n\nThe logs of the QuantumLeap container.\n\n\nThe logs can be retrieved with the \ndocker logs command\n or \ndocker service logs\n if you deployed QL as a service on Swarm. In the first case, you can discover the container id with \ndocker ps -a\n.",
            "title": "Troubleshooting"
        },
        {
            "location": "/user/troubleshooting/#troubleshooting",
            "text": "Something not working as expected? Don't worry! the expected thing is for it not to work :p.  Checkout the following section to make sure you didn't miss a critical step, and if none of that applies to your case, then refer to the  Bug Reporting  section.",
            "title": "Troubleshooting"
        },
        {
            "location": "/user/troubleshooting/#nothing-happens",
            "text": "If you don't see your data being saved in the database, before reporting a bug please ask yourself the following questions:    Have you created a subscription for the entity type you are inserting?    Are you inserting/updating attributes listed in the \"condition\" of the subscription? I.e, will Orion trigger notifications for that insert/update?    Is the location of QuantumLeap expressed in the  notify_url  field of the subscription a resolvable url for the conteinerized Orion? Review the  Usage Section  for more details.    Are you running the different components behind firewalls? If so, did you open the corresponding ports? (See the  Ports  section.)",
            "title": "Nothing Happens"
        },
        {
            "location": "/user/troubleshooting/#bug-reporting",
            "text": "Bugs should be reported in the form of  issues  in the github repository.  Please, look through the open issues before opening a repeated one :)  Include as much context info as possible, also ideally the following things:    The inserted entity that may have caused the problem. E.g:  {\n    'id': 'Room1',\n    'type': 'Room',\n    'attr1': 'blabla',\n    ...\n}    The payload of the subscription(s) that you created.    The logs of the QuantumLeap container.  The logs can be retrieved with the  docker logs command  or  docker service logs  if you deployed QL as a service on Swarm. In the first case, you can discover the container id with  docker ps -a .",
            "title": "Bug reporting"
        },
        {
            "location": "/user/contributing/",
            "text": "Contributions\n\n\nContributions are more than welcome in the form of pull requests.\n\n\nYou can either pick one of the open issues to work on, or provide enhancements according to your own needs. In any case, we suggest getting in touch beforehand to make sure the contribution will be aligned with the current development status.\n\n\nTo contribute:\n\n\n\n\nFork the repository and clone the fork to your local development environment\n\n\nIdentify a modular contribution to the code (avoid too large contributions to simplify review)\n\n\nCreate a branch in your repository where you tackle the \"modular contributions\"\n\n\nFor multiple contributions tackling different functionalities, create different branches\n\n\nFor all the new functionalities provide tests (see \nsetup_dev_env.sh\n and \nrun.sh\n in the root to understand how tests can be run locally)\n\n\nWhen done, verify that all tests are passing\n\n\nIf so, create a pull request against our repository (we cannot review pull requests with failing tests)\n\n\nWait for the review\n\n\nImplement required changes\n\n\nrepeat until approval\n\n\nDone :) You can delete the branch in your repository.\n\n\n\n\nDevelopment Setup and Structure\n\n\nThe development is mostly python3 based for now, and really in the early stages so things will change for sure. For now, you can start with:\n\n\ngit clone https://github.com/smartsdk/ngsi-timeseries-api.git\ncd ngsi-timeseries-api\npython3 -m venv env\npip install -r requirements.txt\n\n# if you want to test everything locally, you'll need to...\nsource setup_dev_env.sh\n\n\n\nPytest is used as the testing framework, but since most of QL's functionality is integration of components, you'll find \ndocker-compose.yml\n files in the test folders to be run as a setup for tests. If you see \n.travis.yml\n file you'll see how they are running today, but probably at some point it's worth exploring pytest-docker plugins.\n\n\nThe \nrequirements.txt\n still needs to be split between testing and production, that's why the docker image is massive for now.\n\n\nIn the file tree structure you can find (to be refactored soon):\n\n\n\n\nngsi-timeseries-api\n\n\nclient\n: holds a simple Orion Context Broker client to ease integration testing. To be moved out of here at some point.\n\n\nexperiments\n: sandbox for quick manual tests to try some stuff and derive new test cases.\n\n\npython-flask\n : will hold the implementation of the swagger-defined API controllers.\n\n\nreporter\n: this module is acting as the receiver of the notifications, who \"parses/validates\" them before being handled to the translators.\n\n\ntranslators\n: specific translators for timeseries databases.\n\n\nutils\n: common shared stuff looking for a better place to live in.",
            "title": "Contributing"
        },
        {
            "location": "/user/contributing/#contributions",
            "text": "Contributions are more than welcome in the form of pull requests.  You can either pick one of the open issues to work on, or provide enhancements according to your own needs. In any case, we suggest getting in touch beforehand to make sure the contribution will be aligned with the current development status.  To contribute:   Fork the repository and clone the fork to your local development environment  Identify a modular contribution to the code (avoid too large contributions to simplify review)  Create a branch in your repository where you tackle the \"modular contributions\"  For multiple contributions tackling different functionalities, create different branches  For all the new functionalities provide tests (see  setup_dev_env.sh  and  run.sh  in the root to understand how tests can be run locally)  When done, verify that all tests are passing  If so, create a pull request against our repository (we cannot review pull requests with failing tests)  Wait for the review  Implement required changes  repeat until approval  Done :) You can delete the branch in your repository.",
            "title": "Contributions"
        },
        {
            "location": "/user/contributing/#development-setup-and-structure",
            "text": "The development is mostly python3 based for now, and really in the early stages so things will change for sure. For now, you can start with:  git clone https://github.com/smartsdk/ngsi-timeseries-api.git\ncd ngsi-timeseries-api\npython3 -m venv env\npip install -r requirements.txt\n\n# if you want to test everything locally, you'll need to...\nsource setup_dev_env.sh  Pytest is used as the testing framework, but since most of QL's functionality is integration of components, you'll find  docker-compose.yml  files in the test folders to be run as a setup for tests. If you see  .travis.yml  file you'll see how they are running today, but probably at some point it's worth exploring pytest-docker plugins.  The  requirements.txt  still needs to be split between testing and production, that's why the docker image is massive for now.  In the file tree structure you can find (to be refactored soon):   ngsi-timeseries-api  client : holds a simple Orion Context Broker client to ease integration testing. To be moved out of here at some point.  experiments : sandbox for quick manual tests to try some stuff and derive new test cases.  python-flask  : will hold the implementation of the swagger-defined API controllers.  reporter : this module is acting as the receiver of the notifications, who \"parses/validates\" them before being handled to the translators.  translators : specific translators for timeseries databases.  utils : common shared stuff looking for a better place to live in.",
            "title": "Development Setup and Structure"
        },
        {
            "location": "/admin/",
            "text": "Installing\n\n\nAt the moment, the only actively supported distribution of QuantumLeap is Docker. Though, you can build and install it from sources, but no guidance is provided for such installation at the moment.\n\n\nIf you need to install Docker, refer to \nDocker Installation\n.\n\n\nYou might also need docker-compose for some cases, which can be installed by running:\n\n\n# Replace 1.16.0 with the version you want. We suggest the latest from https://github.com/docker/compose/releases\ncurl -L https://github.com/docker/compose/releases/download/1.16.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n\n\n\nAlternatively, see the docker-compose \ninstall docs\n for more install options and instructions.\n\n\nThe QuantumLeap Docker Image is hosted at \nhttps://hub.docker.com/r/smartsdk/quantumleap/\n.\n\n\nNow, depending on your scenario, you might have different needs. See from the sections below which fits yours.\n\n\nDeploy QuantumLeap in HA on a Docker Swarm cluster\n\n\nTo deploy QuantumLeap services in HA as a service on a Docker Swarm Cluster, you can follow the instructions in \nthis repository\n.\n\n\nThere you will find instructions on how to deploy not only QuantumLeap but also all the complementary services that typically form part of the deployment scenario.\n\n\nDeploy QuantumLeap using docker-compose (for testing)\n\n\nIf you want to quickly deploy all the components of the \ntypical scenario\n at once to start experimenting with QuantumLeap ASAP, do the following. \nImportant\n: Do not follow this approach for production environments.\n\n\nDownload (or create locally) a copy of \nthis docker-compose.yml\n file.\n\n\nThen start it up:\n\n\n# same path were you have placed the docker-compose.yml\n$ docker-compose up -d\n\n\n\nAfter a while, check that all containers are running (up):\n\n\n$ docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED              STATUS                        PORTS                                                           NAMES\n2ef89b11dd7f        smartsdk/quantumleap   \"/bin/sh -c 'pytho...\"   About a minute ago   Up About a minute             0.0.0.0:8668->8668/tcp                                          grafana_quantumleap_1\nf435868ea042        grafana/grafana        \"/run.sh\"                About a minute ago   Up About a minute             0.0.0.0:3000->3000/tcp                                          grafana_grafana_1\n7bea4ea0b8b4        fiware/orion:1.7.0     \"/usr/bin/contextB...\"   About a minute ago   Up About a minute (healthy)   0.0.0.0:1026->1026/tcp                                          grafana_orion_1\n337cd5b38b82        crate:1.0.5            \"/docker-entrypoin...\"   About a minute ago   Up About a minute             0.0.0.0:4200->4200/tcp, 0.0.0.0:4300->4300/tcp, 5432-5532/tcp   grafana_crate_1\nbe4a72523e69        mongo:3.2              \"docker-entrypoint...\"   About a minute ago   Up About a minute             0.0.0.0:27017->27017/tcp                                        grafana_mongo_1\n\n\n\nNow you're ready to use QuantumLeap as instructed in the \nUser Manual\n.\n\n\nWhen you are done experimenting, remember to teardown the compose.\n\n\n$ docker-compose down -v\n\n\n\nReuse External Orion Instance\n\n\nIf you have already Orion running somewhere else and you just want to deploy QuantumLeap, you can proceed as explained in the previous sections, but before running \ndocker-compose up\n remove from the \ndocker-compose.yml\n file the complete definition of the \norion:\n and \nmongo:\n services. You will also need to remove the references to them in the \ndepends_on:\n section of the other services.\n\n\nSimilarly, if you don't want to use \ngrafana\n, you can remove that service definition as well.\n\n\nThis way, your \ndocker-compose.yml\n file ends up more or less with the following sections only\n\n\nversion: '3'\n\nservices:\n    quantumleap:\n        ...\n    crate:\n        ...\n\nnetworks:\n    ...\n\n\n\nReuse External Orion and CrateDB\n\n\nIf you only need to run QuantumLeap to complete your setup, you can simply run\n\n\ndocker run -d -p 8668:8668 -e \"CRATE_HOST=http://your_crate_location\" smartsdk/quantumleap\n\n\n\nThe environment variable \nCRATE_HOST\n will tell QuantumLeap where to reach \nCrate\n, so you need to provide a reachable hostname where Crate is running. By default QL will append the port \n4200\n to the hostname.\n\n\nFor more options see \ndocker run reference\n.",
            "title": "Introduction"
        },
        {
            "location": "/admin/#installing",
            "text": "At the moment, the only actively supported distribution of QuantumLeap is Docker. Though, you can build and install it from sources, but no guidance is provided for such installation at the moment.  If you need to install Docker, refer to  Docker Installation .  You might also need docker-compose for some cases, which can be installed by running:  # Replace 1.16.0 with the version you want. We suggest the latest from https://github.com/docker/compose/releases\ncurl -L https://github.com/docker/compose/releases/download/1.16.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose  Alternatively, see the docker-compose  install docs  for more install options and instructions.  The QuantumLeap Docker Image is hosted at  https://hub.docker.com/r/smartsdk/quantumleap/ .  Now, depending on your scenario, you might have different needs. See from the sections below which fits yours.",
            "title": "Installing"
        },
        {
            "location": "/admin/#deploy-quantumleap-in-ha-on-a-docker-swarm-cluster",
            "text": "To deploy QuantumLeap services in HA as a service on a Docker Swarm Cluster, you can follow the instructions in  this repository .  There you will find instructions on how to deploy not only QuantumLeap but also all the complementary services that typically form part of the deployment scenario.",
            "title": "Deploy QuantumLeap in HA on a Docker Swarm cluster"
        },
        {
            "location": "/admin/#deploy-quantumleap-using-docker-compose-for-testing",
            "text": "If you want to quickly deploy all the components of the  typical scenario  at once to start experimenting with QuantumLeap ASAP, do the following.  Important : Do not follow this approach for production environments.  Download (or create locally) a copy of  this docker-compose.yml  file.  Then start it up:  # same path were you have placed the docker-compose.yml\n$ docker-compose up -d  After a while, check that all containers are running (up):  $ docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED              STATUS                        PORTS                                                           NAMES\n2ef89b11dd7f        smartsdk/quantumleap   \"/bin/sh -c 'pytho...\"   About a minute ago   Up About a minute             0.0.0.0:8668->8668/tcp                                          grafana_quantumleap_1\nf435868ea042        grafana/grafana        \"/run.sh\"                About a minute ago   Up About a minute             0.0.0.0:3000->3000/tcp                                          grafana_grafana_1\n7bea4ea0b8b4        fiware/orion:1.7.0     \"/usr/bin/contextB...\"   About a minute ago   Up About a minute (healthy)   0.0.0.0:1026->1026/tcp                                          grafana_orion_1\n337cd5b38b82        crate:1.0.5            \"/docker-entrypoin...\"   About a minute ago   Up About a minute             0.0.0.0:4200->4200/tcp, 0.0.0.0:4300->4300/tcp, 5432-5532/tcp   grafana_crate_1\nbe4a72523e69        mongo:3.2              \"docker-entrypoint...\"   About a minute ago   Up About a minute             0.0.0.0:27017->27017/tcp                                        grafana_mongo_1  Now you're ready to use QuantumLeap as instructed in the  User Manual .  When you are done experimenting, remember to teardown the compose.  $ docker-compose down -v",
            "title": "Deploy QuantumLeap using docker-compose (for testing)"
        },
        {
            "location": "/admin/#reuse-external-orion-instance",
            "text": "If you have already Orion running somewhere else and you just want to deploy QuantumLeap, you can proceed as explained in the previous sections, but before running  docker-compose up  remove from the  docker-compose.yml  file the complete definition of the  orion:  and  mongo:  services. You will also need to remove the references to them in the  depends_on:  section of the other services.  Similarly, if you don't want to use  grafana , you can remove that service definition as well.  This way, your  docker-compose.yml  file ends up more or less with the following sections only  version: '3'\n\nservices:\n    quantumleap:\n        ...\n    crate:\n        ...\n\nnetworks:\n    ...",
            "title": "Reuse External Orion Instance"
        },
        {
            "location": "/admin/#reuse-external-orion-and-cratedb",
            "text": "If you only need to run QuantumLeap to complete your setup, you can simply run  docker run -d -p 8668:8668 -e \"CRATE_HOST=http://your_crate_location\" smartsdk/quantumleap  The environment variable  CRATE_HOST  will tell QuantumLeap where to reach  Crate , so you need to provide a reachable hostname where Crate is running. By default QL will append the port  4200  to the hostname.  For more options see  docker run reference .",
            "title": "Reuse External Orion and CrateDB"
        },
        {
            "location": "/admin/ports/",
            "text": "Used Ports\n\n\nThe table below summarizes the default ports for each of the services typically used with QuantumLeap. So, if you run them behind firewalls, remember to include the corresponding rules.\n\n\n\n\n\n\n\n\nProtocol\n\n\nPort\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nTCP\n\n\n1026\n\n\nOrion CB\n\n\n\n\n\n\nTCP\n\n\n8668\n\n\nQuantumLeap's API\n\n\n\n\n\n\nTCP\n\n\n4200\n\n\nCrateDB Admin UI\n\n\n\n\n\n\nTCP\n\n\n4300\n\n\nCrateDB Transport Protocol\n\n\n\n\n\n\nTCP\n\n\n3000\n\n\nGrafana",
            "title": "Ports"
        },
        {
            "location": "/admin/ports/#used-ports",
            "text": "The table below summarizes the default ports for each of the services typically used with QuantumLeap. So, if you run them behind firewalls, remember to include the corresponding rules.     Protocol  Port  Description      TCP  1026  Orion CB    TCP  8668  QuantumLeap's API    TCP  4200  CrateDB Admin UI    TCP  4300  CrateDB Transport Protocol    TCP  3000  Grafana",
            "title": "Used Ports"
        },
        {
            "location": "/admin/crate/",
            "text": "Crate\n\n\nCrate\n is QuantumLeap's default backend where NGSI data will be persisted. Until QuantumLeap implements its querying API, you can interact directly with Crate to query all the data QuantumLeap has stored from the received notifications.\n\n\nIf you followed the \nInstallation Guide\n, you have a ready-to-use Crate instance running in a Docker container.\n\n\nThe easiest way to interact with Crate is using its admin interface, as documented \nhere\n. Alternatively, you can use its \nHTTP api\n, or any of its \nsupported clients\n.\n\n\nYou can learn more about Crate by reading \nthe docs\n.",
            "title": "Crate"
        },
        {
            "location": "/admin/crate/#crate",
            "text": "Crate  is QuantumLeap's default backend where NGSI data will be persisted. Until QuantumLeap implements its querying API, you can interact directly with Crate to query all the data QuantumLeap has stored from the received notifications.  If you followed the  Installation Guide , you have a ready-to-use Crate instance running in a Docker container.  The easiest way to interact with Crate is using its admin interface, as documented  here . Alternatively, you can use its  HTTP api , or any of its  supported clients .  You can learn more about Crate by reading  the docs .",
            "title": "Crate"
        },
        {
            "location": "/admin/grafana/",
            "text": "Grafana\n\n\nGrafana\n is a powerful visualization tool that we can use to display graphics of the persisted data.\n\n\nIn order to read data from a \nCrate\n database, grafana leverages on the \nGrafana Datasource Plugin for CrateDB\n.\n\n\nIf you followed the \nInstallation Guide\n, you have already Grafana running in a Docker container, with the aforementioned plugin already installed.\n\n\nFor now, crate data sources are restricted to a single table, and Quantum leap creates one table per entity type; hence, you'll have to create one data source per entity type. If this is a problem/limitation for you, open an issue in quantumleap's repo and we can see how to work around.\n\n\nConfiguring the DataSource\n\n\nExplore your deployed grafana instance (e.g http://localhost:3000). If you didn't change the defaults, \nadmin/admin\n are the default credentials.\n\n\nGo to \nAdd data source\n and fill in the required fields, with the following observations:\n\n\n\n\nName\n: This is the name you want for the Datasource. We recommend naming it after the entity type (i.e, the table you will connect to).\n\n\nType\n: Use \nCrate\n. If you don't see \nCrate\n, check your installation of the datasource plugin.\n\n\nUrl\n: The full url where cratedb was deployed.\n\n\nAccess\n: Use \ndirect\n if you're deploying everything locally. If you are deploying crate behind a proxy (as in the case of \nHA deployment\n), choose the \nproxy\n option instead.\n\n\nSchema\n: The schema where the table is defined. By default in crate use \ndoc\n.\n\n\nTable\n: The name of the table of the entity. See the \nData Retrieval\n section to know how table names are defined.\n\n\nTime column\n: The name of the column used as time index. By default is 'time_index', as explained in the \nThe Time Index\n section.\n\n\n\n\nImage below as an example\n\n\n\nUsing the DataSource in your Graph\n\n\nHaving your datasource setup, you can start using it in the different visualization widgets.\n\n\nThe following is an example of a Graph using a Crate datasource. Note the selection of the datasource (called CrateDB in this case), as well as the specification of the table in the \nfrom\n field. Note that the table is referenced as \nschema.tablename\n (e.g: \ndoc.etairqualityobserved\n)",
            "title": "Grafana"
        },
        {
            "location": "/admin/grafana/#grafana",
            "text": "Grafana  is a powerful visualization tool that we can use to display graphics of the persisted data.  In order to read data from a  Crate  database, grafana leverages on the  Grafana Datasource Plugin for CrateDB .  If you followed the  Installation Guide , you have already Grafana running in a Docker container, with the aforementioned plugin already installed.  For now, crate data sources are restricted to a single table, and Quantum leap creates one table per entity type; hence, you'll have to create one data source per entity type. If this is a problem/limitation for you, open an issue in quantumleap's repo and we can see how to work around.",
            "title": "Grafana"
        },
        {
            "location": "/admin/grafana/#configuring-the-datasource",
            "text": "Explore your deployed grafana instance (e.g http://localhost:3000). If you didn't change the defaults,  admin/admin  are the default credentials.  Go to  Add data source  and fill in the required fields, with the following observations:   Name : This is the name you want for the Datasource. We recommend naming it after the entity type (i.e, the table you will connect to).  Type : Use  Crate . If you don't see  Crate , check your installation of the datasource plugin.  Url : The full url where cratedb was deployed.  Access : Use  direct  if you're deploying everything locally. If you are deploying crate behind a proxy (as in the case of  HA deployment ), choose the  proxy  option instead.  Schema : The schema where the table is defined. By default in crate use  doc .  Table : The name of the table of the entity. See the  Data Retrieval  section to know how table names are defined.  Time column : The name of the column used as time index. By default is 'time_index', as explained in the  The Time Index  section.   Image below as an example",
            "title": "Configuring the DataSource"
        },
        {
            "location": "/admin/grafana/#using-the-datasource-in-your-graph",
            "text": "Having your datasource setup, you can start using it in the different visualization widgets.  The following is an example of a Graph using a Crate datasource. Note the selection of the datasource (called CrateDB in this case), as well as the specification of the table in the  from  field. Note that the table is referenced as  schema.tablename  (e.g:  doc.etairqualityobserved )",
            "title": "Using the DataSource in your Graph"
        }
    ]
}
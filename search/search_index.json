{
    "docs": [
        {
            "location": "/",
            "text": "QuantumLeap\n\n\nOverview\n\n\nQuantumLeap is the first implementation of an API that supports the storage of\nNGSI \nFIWARE NGSIv2\n data into a\n\ntime-series database\n.\n\n\nIn the end, it has similar goals to those of \nFIWARE's Comet STH\n.\nHowever, Comet does not yet support NGSIv2, it's strongly tied to MongoDB, and\nsome of the conditions and constraints under which it was developed are no\nlonger hold. That being said, there is nothing wrong with it; this is just an\nexploration on a new way to provide historical data for FIWARE NGSIv2 with\ndifferent time-series databases as backend.\n\n\nThe idea is to keep the time-series database swappable so as to look forward to\nhaving support for different ones. We started testing\n\nInfluxDB\n, \nRethinkDB\n\nand \nCrate\n. However, we have decided for now to focus the\ndevelopment on the translator for \nCrate\n because of the\nfollowing advantages:\n\n\n\n\nEasy scalability with \ncontainerised database cluster\n\nout of the box.\n\n\nGeo-queries\n\nsupport out of the box\n\n\nNice \nSQL-like querying language\n\nto work with\n\n\nSupported integration\n\nwith visualisation tools like \nGrafana\n\n\n\n\nTypical Usage and How it works\n\n\nThe typical usage scenario for QuantumLeap would be the following (notice the\nnumbering of the events)...\n\n\n\n\nThe idea of \nQuantumLeap\n is pretty straightforward. By leveraging on the \nNGSIv2 notifications mechanism\n,\nclients first create an Orion subscription \n(1)\n to notify QuantumLeap of the\nchanges in the entities they care about. This can be done either through\n\nQuantumLeap\n's API or directly talking to \nOrion\n. Details of this process are\nexplained in the \nOrion Subscription part of the User Manual\n.\n\n\nThen, new values arrive in \nOrion Context Broker\n\n\n(2)\n for the entities of interest, for example from a whole \nIoT layer\n\ngoverned by 1 or more \nIoT Agents\n\npushing data in NGSI format. Consequently, notifications will arrive to\nQuantumLeap's API \n/v2/notify\n endpoint \n(3)\n.\n\n\nQuantumLeap's \nReporter\n submodule will parse and validate the received\nnotification and eventually feed it to the configured \nTranslator\n. The\nTranslator is ultimately responsible for persisting the NGSI information to the\nconfigured times-series database cluster.\n\n\nThe current API includes some endpoints for raw and aggregated data retrieval\n\n(4)\n for clients to query historical data. It also supports deletion of\nhistorical records. Please note not all endpoints are currently implemented in\nQL. For more info about the API, you can refer to the\n\nNGSI-TSDB specification\n.\n\n\nFor the visualisation of data \n(5)\n, at the time being we are using\n\nGrafana\n, complemented with open source plugins for the\ndatabases. In the future, we could envision a grafana plugin for direct\ninteraction with QL's API.\n\n\nMore information\n\n\n\n\nRefer to the \nAdmin Guide\n to learn more about installing\nQuantumLeap and getting it running.\n\n\nRefer to the \nUser Manual\n to learn more about how to use it\nand connect it to other complementary services.\n\n\nHave a look at the \nSmartSDK guided tour\n\nfor more examples of QuantumLeap usage.",
            "title": "Home"
        },
        {
            "location": "/#quantumleap",
            "text": "",
            "title": "QuantumLeap"
        },
        {
            "location": "/#overview",
            "text": "QuantumLeap is the first implementation of an API that supports the storage of\nNGSI  FIWARE NGSIv2  data into a time-series database .  In the end, it has similar goals to those of  FIWARE's Comet STH .\nHowever, Comet does not yet support NGSIv2, it's strongly tied to MongoDB, and\nsome of the conditions and constraints under which it was developed are no\nlonger hold. That being said, there is nothing wrong with it; this is just an\nexploration on a new way to provide historical data for FIWARE NGSIv2 with\ndifferent time-series databases as backend.  The idea is to keep the time-series database swappable so as to look forward to\nhaving support for different ones. We started testing InfluxDB ,  RethinkDB \nand  Crate . However, we have decided for now to focus the\ndevelopment on the translator for  Crate  because of the\nfollowing advantages:   Easy scalability with  containerised database cluster \nout of the box.  Geo-queries \nsupport out of the box  Nice  SQL-like querying language \nto work with  Supported integration \nwith visualisation tools like  Grafana",
            "title": "Overview"
        },
        {
            "location": "/#typical-usage-and-how-it-works",
            "text": "The typical usage scenario for QuantumLeap would be the following (notice the\nnumbering of the events)...   The idea of  QuantumLeap  is pretty straightforward. By leveraging on the  NGSIv2 notifications mechanism ,\nclients first create an Orion subscription  (1)  to notify QuantumLeap of the\nchanges in the entities they care about. This can be done either through QuantumLeap 's API or directly talking to  Orion . Details of this process are\nexplained in the  Orion Subscription part of the User Manual .  Then, new values arrive in  Orion Context Broker  (2)  for the entities of interest, for example from a whole  IoT layer \ngoverned by 1 or more  IoT Agents \npushing data in NGSI format. Consequently, notifications will arrive to\nQuantumLeap's API  /v2/notify  endpoint  (3) .  QuantumLeap's  Reporter  submodule will parse and validate the received\nnotification and eventually feed it to the configured  Translator . The\nTranslator is ultimately responsible for persisting the NGSI information to the\nconfigured times-series database cluster.  The current API includes some endpoints for raw and aggregated data retrieval (4)  for clients to query historical data. It also supports deletion of\nhistorical records. Please note not all endpoints are currently implemented in\nQL. For more info about the API, you can refer to the NGSI-TSDB specification .  For the visualisation of data  (5) , at the time being we are using Grafana , complemented with open source plugins for the\ndatabases. In the future, we could envision a grafana plugin for direct\ninteraction with QL's API.",
            "title": "Typical Usage and How it works"
        },
        {
            "location": "/#more-information",
            "text": "Refer to the  Admin Guide  to learn more about installing\nQuantumLeap and getting it running.  Refer to the  User Manual  to learn more about how to use it\nand connect it to other complementary services.  Have a look at the  SmartSDK guided tour \nfor more examples of QuantumLeap usage.",
            "title": "More information"
        },
        {
            "location": "/user/",
            "text": "Using QuantumLeap\n\n\nFirst you need to have QuantumLeap and its complementary services running (of\ncourse). Refer to the \nInstallation Manual\n for instructions.\n\n\nThen, you need to connect \nOrion Context Broker\n to QuantumLeap through an \nNGSIv2\nsubscription\n\nfor each \nEntity Type\n\nwhose historical data you are interested in.\n\n\nNot an Orion expert yet? No problem, you can create the subscription through\nQuantumLeap's API. However, you will still need to understand the basics of\nhow subscriptions and notifications work, so take a time to read\n\nthe docs\n.\n\n\nHistorical data for each entity type will be persisted as long as the\nsubscription is active, correctly configured and the entity in the notification\nis NGSI compliant.\n\n\nSo, summing up, the usage flow is therefore the following...\n\n\n\n\nCreate an Orion subscription for each entity type of your interest\n\n\nInsert/Update your data in Orion as usual\n\n\nYour historical data will be persisted in QuantumLeap's database\n\n\n\n\nLet's take a closer look at each step.\n\n\nOrion Subscription\n\n\nAs stated before, the link between Orion and QuantumLeap is established\nthrough a subscription you need to create. It is therefore important that you\nunderstand well how the NGSIv2 Subscription mechanism works. This is carefully\nexplained in the corresponding section of \nOrion docs\n.\n\n\nTo create the subscription, QuantumLeap offers an API endpoint documented\n\nhere\n.\n\n\nAlternatively, you can directly talk to Orion and create the subscription as you\nprefer. Here's an example of the payload of the subscription you need to create\nin Orion to establish the link Orion-QuantumLeap.\n\n\n    {\n        \"description\": \"Test subscription\",\n        \"subject\": {\n            \"entities\": [\n            {\n                \"idPattern\": \".*\",\n                \"type\": \"Room\"\n            }\n            ],\n            \"condition\": {\n                \"attrs\": [\n                \"temperature\"\n                ]\n            }\n        },\n        \"notification\": {\n            \"http\": {\n                \"url\": \"http://quantumleap:8668/v2/notify\"\n            },\n            \"attrs\": [\n            \"temperature\"\n            ],\n            \"metadata\": [\"dateCreated\", \"dateModified\"]\n        },\n        \"throttling\": 5\n    }\n\n\n\n\nImportant things to notice from the subscription.\n\n\n\n\n\n\nNotifications must come in complete \nNGSI JSON Entity Representation\n\n form. Other forms, such as the \nsimplified entity representation\n\n are \nNOT\n supported by QL because they lack information on attribute types,\n required by QL to make proper translations. This means, \nDO NOT\n use options\n like \n\"attrsFormat\": \"keyValues\"\n\n\n\n\n\n\nThe \n\"url\"\n field of the subscription specifies where Orion will send the\nnotifications. I.e, this must be QuantumLeap's \n/v2/notify\n endpoint.\nBy default, QuantumLeap listens at port \n8668\n. This url must be resolvable\nfrom Orion's container, so avoid using \nlocalhost\n or something that will not\ntranslate either by Docker, your \n/etc/hosts\n or DNS to the endpoint where\nQuantumLeap is running.\n\n\n\n\n\n\nThough not compulsory, it is highly recommended to include the\n\n\"metadata\": [\"dateCreated\", \"dateModified\"]\n part in the \nnotification\n\npart of the subscription. This instructs Orion to include the modification time\nof the attributes in the notification. This timestamp will be used as the time\nindex in the database. If this is somehow missing, QuantumLeap will use its\ncurrent system time at which the notification arrived, which might not be\nexactly what you want.\n\n\n\n\n\n\nYou can create any valid NGSI subscription for your entities respecting the\nprevious rules.\n\n\n\n\n\n\nData Insertion\n\n\nBy now, it should be clear you don't typically insert data directly into\nQuantumLeap. You insert into Orion and Orion notifies QuantumLeap.\nFor inserts and updates in Orion, refer to the \ndocs\n.\n\n\nIt's not a problem if inserts were done before you created the\nsubscription. Of course, you will only get historical records of the updates\nhappening after the subscription was created.\n\n\nHere's an example of an insert payload to Orion that will generate a\nnotification to QuantumLeap based on the \"Test subscription\" example shown\nbefore.\n\n\n{\n    \"id\": \"Room1\",\n    \"type\": \"Room\",\n    \"temperature\": {\n        \"value\": 24.2,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    },\n    \"pressure\": {\n        \"value\": 720,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    }\n    \"colour\": {\n        \"value\": \"white\",\n        \"type\": \"Text\",\n        \"metadata\": {}\n    }\n}\n\n\n\n\nIf you have a custom scenario and still want to directly insert to QuantumLeap,\nit is not impossible. However, you will have to use the same payload Orion uses\nin the Notification. Also, you will need attention to some other details you\nwill have to discover on your own. This is not fully documented because it's not\nconsidered a common workflow.\n\n\nAttributes DataType Translation\n\n\nYou need to make sure your NGSI entities are using the valid NGSI types for the\nattributes, which are documented in the \nSpecification\n section of the \nNGSI API\n. See the first\ncolumn of the translation table below, and mind its capitalisation.\n\n\nThe table below shows which attribute types will be translated to which\n\nCrate Data Types\n.\n\n\nCrate Translation Table\n\n\n\n\n\n\n\n\nNGSI Type\n\n\nCrate Type\n\n\nObservation\n\n\n\n\n\n\n\n\n\n\nArray\n\n\narray(string)\n\n\nIssue 36: Support arrays of other types\n\n\n\n\n\n\nBoolean\n\n\nboolean\n\n\n-\n\n\n\n\n\n\nDateTime\n\n\ntimestamp\n\n\n'ISO8601' can be used as equivalent of 'DateTime'.\n\n\n\n\n\n\nInteger\n\n\nlong\n\n\n-\n\n\n\n\n\n\ngeo:point\n\n\ngeo_point\n\n\nAttention!\n NGSI uses \"lat, long\" order whereas Crate stores points in [long, lat] order.\n\n\n\n\n\n\ngeo:json\n\n\ngeo_shape\n\n\n-\n\n\n\n\n\n\nNumber\n\n\nfloat\n\n\n-\n\n\n\n\n\n\nText\n\n\nstring\n\n\nThis is the default type if the provided NGSI Type is unsupported or wrong.\n\n\n\n\n\n\nStructuredValue\n\n\nobject\n\n\n-\n\n\n\n\n\n\n\n\nIf the type of any of the received attributes is not present in the column\n\nNGSI Type\n of the previous table, the value of such attribute will be treated\ninternally as a string. So, if you use \nFloat\n for your attribute type (not\nvalid), your attribute will be stored as a \nstring\n.\n\n\nRestrictions and Limitations\n\n\n\n\n\n\nYou cannot have two entity types with the same name but different\ncapitalisation. E.g: \nPreprocessor\n and \npreProcessor\n. The same applies for\nattribute names of a given entity. I.e, attributes \nhotSpot\n and \nhotspot\n\nwill be treated as the same. These are rare corner-cases, but it is worth\nkeeping in mind this. Ultimately, the correct naming of types and attributes\nshould respect the naming guidelines explained\n\nhere\n.\n\n\n\n\n\n\nAttributes metadata are still not being persisted. See \nIssue 12\n\n\n\n\n\n\nData Retrieval\n\n\nTo retrieve historical data from QuantumLeap, you can use the API endpoints\ndocumented \nhere\n.\nNote there are a lot of possibilities, but not all of them are fully\nimplemented yet.\n\n\nIf you want to, you can interact directly with the database. For more details\nrefer to the \nCrate\n section of the docs. What you need to\nknow in this case is that QuantumLeap will create one table per each entity\ntype. Table names are formed with a prefix (et) plus the lowercase version of\nthe entity type. I.e, if your entity type is \nAirQualityObserved\n, the\ncorresponding table name will be \netairqualityobserved\n. Table names should be\nprefixed also with the schema where they are defined. See the\n\nMulti-tenancy\n section below.\n\n\nFinally, you can interact with your data visually using \nGrafana\n.\nSee the \nGrafana\n section of the docs to see how.\n\n\nTime Index\n\n\nA fundamental element in the time-series database is the time index. You may be\nwondering... where is it stored?\n\n\nQuantumLeap will persist the \ntime index\n for each notification in a special\ncolumn called \ntime_index\n.  If you payed attention in the\n\nOrion Subscription section\n, you know at least which\nvalue is used as the time index. This is, the \n\"dateModified\"\n value notified\nby Orion or, if you missed that option in the subscription, the notification\narrival time.\n\n\nIn the future, this could be more flexible and allow users to define any\n\nDateTime\n attribute to be used as the time index.\n\n\nData Removal\n\n\nYou can remove historical data from QuantumLeap in two different ways.\n\n\nTo remove all records of a given entity, use \nthis API endpoint\n.\n\n\nTo remove all records of all entities of a given type, use \nthis API endpoint\n.\n\n\nUse the filters to delete only records in certain intervals of time.\n\n\nMulti-tenancy\n\n\nQuantumLeap supports the use of different tenants, just like Orion does with\nthe usage FIWARE headers documented \nhere\n.\n\n\nRecall the use of tenancy headers (\nFiware-Service\n and \nFiware-ServicePath\n) is\noptional. Data insertion and retrieval will work by default without those.\nHowever, if you use headers for the insertion, you need to specify the same ones\nwhen querying data.\n\n\nNote in the case of QuantumLeap, the headers at the time of \"insertion\" should\nactually be used by the client at the time of creating the\n\nSubscription to Orion\n and also by the device when pushing data to Orion.\nAs mentioned, the same headers will have to be used in order to retrieve such\ndata.\n\n\nIn case you are interacting directly with the database, you need to know that\nQuantumLeap will use the \nFIWARE-Service\n as the \ndatabase scheme\n for crate,\nwith a specific prefix. This way, if you insert an entity of type \nRoom\n in the\nusing the \nFiware-Service: magic\n header, you should expect to find your table\nat \nmtmagic.etroom\n. This information is also useful for example if you are\nconfiguring the Grafana datasource, as explained in the \nGrafana section\n of the docs.\n\n\nGeoCoding\n\n\nThis is an optional and experimental feature of QuantumLeap, which helps\nharmonising the way location information is stored in the historical records.\n\n\nThe idea is that if entities arrive in QuantumLeap with an attribute of type\n\nStructuredValue\n and named \naddress\n, QuantumLeap interprets this as an address\nfield typically found in the \nFIWARE Data Models\n.\nIt then adds to the entity an attribute called \nlocation\n of the corresponding\ngeo-type. This means, if the address is a complete address with city,\nstreet name and postal number it maps to a point and hence the generated\nattribute will be of type \ngeo:point\n. Without a postal number, the address\nwill represent the street (if any) or the city boundaries (if any) or even the\ncountry boundaries. In these cases the generated location will be of the\n\ngeo:json\n form and will contain the values of such shape.\n\n\nWARNING:\n This feature uses \nOpenStreetMap\n\nand its Nominatim service. As such, you need to be aware of its \ncopyright notes\n and most importantly of their\nUsage Policies (\nAPI Usage Policy\n\n, \nNominatim Usage Policy\n\nYou should not abuse of this free service and you should cache your requests.\nThis is why you need to specify a cache in order to enable the geocoding.\nQuantumLeap uses \nRedis\n.\n\n\nSo, to enable this feature, you need to pass (at initialisation time) to the\nQuantumLeap container the environment variable \nUSE_GEOCODING\n set to \nTrue\n\nand the environment variables \nREDIS_HOST\n and \nREDIS_PORT\n respectively set to\nthe location of your REDIS instance and its access port. See the \ndocker-compose-dev.yml\n for example.",
            "title": "Introduction"
        },
        {
            "location": "/user/#using-quantumleap",
            "text": "First you need to have QuantumLeap and its complementary services running (of\ncourse). Refer to the  Installation Manual  for instructions.  Then, you need to connect  Orion Context Broker  to QuantumLeap through an  NGSIv2\nsubscription \nfor each  Entity Type \nwhose historical data you are interested in.  Not an Orion expert yet? No problem, you can create the subscription through\nQuantumLeap's API. However, you will still need to understand the basics of\nhow subscriptions and notifications work, so take a time to read the docs .  Historical data for each entity type will be persisted as long as the\nsubscription is active, correctly configured and the entity in the notification\nis NGSI compliant.  So, summing up, the usage flow is therefore the following...   Create an Orion subscription for each entity type of your interest  Insert/Update your data in Orion as usual  Your historical data will be persisted in QuantumLeap's database   Let's take a closer look at each step.",
            "title": "Using QuantumLeap"
        },
        {
            "location": "/user/#orion-subscription",
            "text": "As stated before, the link between Orion and QuantumLeap is established\nthrough a subscription you need to create. It is therefore important that you\nunderstand well how the NGSIv2 Subscription mechanism works. This is carefully\nexplained in the corresponding section of  Orion docs .  To create the subscription, QuantumLeap offers an API endpoint documented here .  Alternatively, you can directly talk to Orion and create the subscription as you\nprefer. Here's an example of the payload of the subscription you need to create\nin Orion to establish the link Orion-QuantumLeap.      {\n        \"description\": \"Test subscription\",\n        \"subject\": {\n            \"entities\": [\n            {\n                \"idPattern\": \".*\",\n                \"type\": \"Room\"\n            }\n            ],\n            \"condition\": {\n                \"attrs\": [\n                \"temperature\"\n                ]\n            }\n        },\n        \"notification\": {\n            \"http\": {\n                \"url\": \"http://quantumleap:8668/v2/notify\"\n            },\n            \"attrs\": [\n            \"temperature\"\n            ],\n            \"metadata\": [\"dateCreated\", \"dateModified\"]\n        },\n        \"throttling\": 5\n    }  Important things to notice from the subscription.    Notifications must come in complete  NGSI JSON Entity Representation \n form. Other forms, such as the  simplified entity representation \n are  NOT  supported by QL because they lack information on attribute types,\n required by QL to make proper translations. This means,  DO NOT  use options\n like  \"attrsFormat\": \"keyValues\"    The  \"url\"  field of the subscription specifies where Orion will send the\nnotifications. I.e, this must be QuantumLeap's  /v2/notify  endpoint.\nBy default, QuantumLeap listens at port  8668 . This url must be resolvable\nfrom Orion's container, so avoid using  localhost  or something that will not\ntranslate either by Docker, your  /etc/hosts  or DNS to the endpoint where\nQuantumLeap is running.    Though not compulsory, it is highly recommended to include the \"metadata\": [\"dateCreated\", \"dateModified\"]  part in the  notification \npart of the subscription. This instructs Orion to include the modification time\nof the attributes in the notification. This timestamp will be used as the time\nindex in the database. If this is somehow missing, QuantumLeap will use its\ncurrent system time at which the notification arrived, which might not be\nexactly what you want.    You can create any valid NGSI subscription for your entities respecting the\nprevious rules.",
            "title": "Orion Subscription"
        },
        {
            "location": "/user/#data-insertion",
            "text": "By now, it should be clear you don't typically insert data directly into\nQuantumLeap. You insert into Orion and Orion notifies QuantumLeap.\nFor inserts and updates in Orion, refer to the  docs .  It's not a problem if inserts were done before you created the\nsubscription. Of course, you will only get historical records of the updates\nhappening after the subscription was created.  Here's an example of an insert payload to Orion that will generate a\nnotification to QuantumLeap based on the \"Test subscription\" example shown\nbefore.  {\n    \"id\": \"Room1\",\n    \"type\": \"Room\",\n    \"temperature\": {\n        \"value\": 24.2,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    },\n    \"pressure\": {\n        \"value\": 720,\n        \"type\": \"Number\",\n        \"metadata\": {}\n    }\n    \"colour\": {\n        \"value\": \"white\",\n        \"type\": \"Text\",\n        \"metadata\": {}\n    }\n}  If you have a custom scenario and still want to directly insert to QuantumLeap,\nit is not impossible. However, you will have to use the same payload Orion uses\nin the Notification. Also, you will need attention to some other details you\nwill have to discover on your own. This is not fully documented because it's not\nconsidered a common workflow.",
            "title": "Data Insertion"
        },
        {
            "location": "/user/#attributes-datatype-translation",
            "text": "You need to make sure your NGSI entities are using the valid NGSI types for the\nattributes, which are documented in the  Specification  section of the  NGSI API . See the first\ncolumn of the translation table below, and mind its capitalisation.  The table below shows which attribute types will be translated to which Crate Data Types .  Crate Translation Table     NGSI Type  Crate Type  Observation      Array  array(string)  Issue 36: Support arrays of other types    Boolean  boolean  -    DateTime  timestamp  'ISO8601' can be used as equivalent of 'DateTime'.    Integer  long  -    geo:point  geo_point  Attention!  NGSI uses \"lat, long\" order whereas Crate stores points in [long, lat] order.    geo:json  geo_shape  -    Number  float  -    Text  string  This is the default type if the provided NGSI Type is unsupported or wrong.    StructuredValue  object  -     If the type of any of the received attributes is not present in the column NGSI Type  of the previous table, the value of such attribute will be treated\ninternally as a string. So, if you use  Float  for your attribute type (not\nvalid), your attribute will be stored as a  string .",
            "title": "Attributes DataType Translation"
        },
        {
            "location": "/user/#restrictions-and-limitations",
            "text": "You cannot have two entity types with the same name but different\ncapitalisation. E.g:  Preprocessor  and  preProcessor . The same applies for\nattribute names of a given entity. I.e, attributes  hotSpot  and  hotspot \nwill be treated as the same. These are rare corner-cases, but it is worth\nkeeping in mind this. Ultimately, the correct naming of types and attributes\nshould respect the naming guidelines explained here .    Attributes metadata are still not being persisted. See  Issue 12",
            "title": "Restrictions and Limitations"
        },
        {
            "location": "/user/#data-retrieval",
            "text": "To retrieve historical data from QuantumLeap, you can use the API endpoints\ndocumented  here .\nNote there are a lot of possibilities, but not all of them are fully\nimplemented yet.  If you want to, you can interact directly with the database. For more details\nrefer to the  Crate  section of the docs. What you need to\nknow in this case is that QuantumLeap will create one table per each entity\ntype. Table names are formed with a prefix (et) plus the lowercase version of\nthe entity type. I.e, if your entity type is  AirQualityObserved , the\ncorresponding table name will be  etairqualityobserved . Table names should be\nprefixed also with the schema where they are defined. See the Multi-tenancy  section below.  Finally, you can interact with your data visually using  Grafana .\nSee the  Grafana  section of the docs to see how.",
            "title": "Data Retrieval"
        },
        {
            "location": "/user/#time-index",
            "text": "A fundamental element in the time-series database is the time index. You may be\nwondering... where is it stored?  QuantumLeap will persist the  time index  for each notification in a special\ncolumn called  time_index .  If you payed attention in the Orion Subscription section , you know at least which\nvalue is used as the time index. This is, the  \"dateModified\"  value notified\nby Orion or, if you missed that option in the subscription, the notification\narrival time.  In the future, this could be more flexible and allow users to define any DateTime  attribute to be used as the time index.",
            "title": "Time Index"
        },
        {
            "location": "/user/#data-removal",
            "text": "You can remove historical data from QuantumLeap in two different ways.  To remove all records of a given entity, use  this API endpoint .  To remove all records of all entities of a given type, use  this API endpoint .  Use the filters to delete only records in certain intervals of time.",
            "title": "Data Removal"
        },
        {
            "location": "/user/#multi-tenancy",
            "text": "QuantumLeap supports the use of different tenants, just like Orion does with\nthe usage FIWARE headers documented  here .  Recall the use of tenancy headers ( Fiware-Service  and  Fiware-ServicePath ) is\noptional. Data insertion and retrieval will work by default without those.\nHowever, if you use headers for the insertion, you need to specify the same ones\nwhen querying data.  Note in the case of QuantumLeap, the headers at the time of \"insertion\" should\nactually be used by the client at the time of creating the Subscription to Orion  and also by the device when pushing data to Orion.\nAs mentioned, the same headers will have to be used in order to retrieve such\ndata.  In case you are interacting directly with the database, you need to know that\nQuantumLeap will use the  FIWARE-Service  as the  database scheme  for crate,\nwith a specific prefix. This way, if you insert an entity of type  Room  in the\nusing the  Fiware-Service: magic  header, you should expect to find your table\nat  mtmagic.etroom . This information is also useful for example if you are\nconfiguring the Grafana datasource, as explained in the  Grafana section  of the docs.",
            "title": "Multi-tenancy"
        },
        {
            "location": "/user/#geocoding",
            "text": "This is an optional and experimental feature of QuantumLeap, which helps\nharmonising the way location information is stored in the historical records.  The idea is that if entities arrive in QuantumLeap with an attribute of type StructuredValue  and named  address , QuantumLeap interprets this as an address\nfield typically found in the  FIWARE Data Models .\nIt then adds to the entity an attribute called  location  of the corresponding\ngeo-type. This means, if the address is a complete address with city,\nstreet name and postal number it maps to a point and hence the generated\nattribute will be of type  geo:point . Without a postal number, the address\nwill represent the street (if any) or the city boundaries (if any) or even the\ncountry boundaries. In these cases the generated location will be of the geo:json  form and will contain the values of such shape.  WARNING:  This feature uses  OpenStreetMap \nand its Nominatim service. As such, you need to be aware of its  copyright notes  and most importantly of their\nUsage Policies ( API Usage Policy \n,  Nominatim Usage Policy \nYou should not abuse of this free service and you should cache your requests.\nThis is why you need to specify a cache in order to enable the geocoding.\nQuantumLeap uses  Redis .  So, to enable this feature, you need to pass (at initialisation time) to the\nQuantumLeap container the environment variable  USE_GEOCODING  set to  True \nand the environment variables  REDIS_HOST  and  REDIS_PORT  respectively set to\nthe location of your REDIS instance and its access port. See the  docker-compose-dev.yml  for example.",
            "title": "GeoCoding"
        },
        {
            "location": "/user/troubleshooting/",
            "text": "Troubleshooting\n\n\nSomething not working as expected? Don't worry! the expected thing is for it\nnot to work :p.\n\n\nCheckout the following section to make sure you didn't miss a critical step,\nand if none of that applies to your case, then refer to the \nBug reporting\n\nsection.\n\n\nNothing happens\n\n\nIf you don't see your data being saved in the database, before reporting a bug\nplease ask yourself the following questions:\n\n\n\n\n\n\nHave you created a subscription for the entity type you are inserting? Is\nthe subscription NGSIv2 and WITHOUT the \"keyValues\" option?. Review the \nOrion Subscriptions Docs\n.\n\n\n\n\n\n\nAre you inserting/updating attributes listed in the \"condition\" of the\nsubscription? I.e, will Orion trigger notifications for that insert/update?\n\n\n\n\n\n\nCan you see such subscription if you query Orion subscriptions? When is its\n\"last_success\"?\n\n\n\n\n\n\nIs the location of QuantumLeap expressed in the \nnotify_url\n field of the\nsubscription a resolvable url for the containerised Orion? Review the \nUsage Section\n for more details.\n\n\n\n\n\n\nAre you running the different components behind firewalls? If so, did you\nopen the corresponding ports? (See the \nPorts\n section.)\n\n\n\n\n\n\nCannot retrieve data\n\n\n\n\n\n\nAre you using the correct FIWARE headers for the tenant? Refer to the \nMulti-tenancy\n\npart of the docs.\n\n\n\n\n\n\nIs the endpoint you are using implemented? Note for now some of them are not.\nThese are flagged in the API specification.\n\n\n\n\n\n\nHave a look at the message in the returned body for hints of what could have\ngone wrong. You may be missing an important parameter in your request.\n\n\n\n\n\n\nBug reporting\n\n\nBugs should be reported in the form of \nissues\n in the github\nrepository.\n\n\nPlease, look through the open issues before opening a repeated one :)\n\n\nInclude as much context info as possible, also ideally the following things:\n\n\n\n\n\n\nThe inserted entity that may have caused the problem. E.g:\n\n\n{\n    'id': 'MyEntityId',\n    'type': 'MyEntityType',\n    'attr1': 'blabla',\n    ...\n}\n\n\n\n\n\n\n\nThe payload of the subscription(s) that you created. See \nthis section\n\nof Orion documentation.\n\n\n\n\n\n\nThe logs of the QuantumLeap container.\n\n\nThe logs can be retrieved with the \ndocker logs command\n\nor \ndocker service logs\n\nif you deployed QL as a service. In the first case, you can discover the\ncontainer id with \ndocker ps -a\n. In the second case, use\n\ndocker service ls\n to find the service name.",
            "title": "Troubleshooting"
        },
        {
            "location": "/user/troubleshooting/#troubleshooting",
            "text": "Something not working as expected? Don't worry! the expected thing is for it\nnot to work :p.  Checkout the following section to make sure you didn't miss a critical step,\nand if none of that applies to your case, then refer to the  Bug reporting \nsection.",
            "title": "Troubleshooting"
        },
        {
            "location": "/user/troubleshooting/#nothing-happens",
            "text": "If you don't see your data being saved in the database, before reporting a bug\nplease ask yourself the following questions:    Have you created a subscription for the entity type you are inserting? Is\nthe subscription NGSIv2 and WITHOUT the \"keyValues\" option?. Review the  Orion Subscriptions Docs .    Are you inserting/updating attributes listed in the \"condition\" of the\nsubscription? I.e, will Orion trigger notifications for that insert/update?    Can you see such subscription if you query Orion subscriptions? When is its\n\"last_success\"?    Is the location of QuantumLeap expressed in the  notify_url  field of the\nsubscription a resolvable url for the containerised Orion? Review the  Usage Section  for more details.    Are you running the different components behind firewalls? If so, did you\nopen the corresponding ports? (See the  Ports  section.)",
            "title": "Nothing happens"
        },
        {
            "location": "/user/troubleshooting/#cannot-retrieve-data",
            "text": "Are you using the correct FIWARE headers for the tenant? Refer to the  Multi-tenancy \npart of the docs.    Is the endpoint you are using implemented? Note for now some of them are not.\nThese are flagged in the API specification.    Have a look at the message in the returned body for hints of what could have\ngone wrong. You may be missing an important parameter in your request.",
            "title": "Cannot retrieve data"
        },
        {
            "location": "/user/troubleshooting/#bug-reporting",
            "text": "Bugs should be reported in the form of  issues  in the github\nrepository.  Please, look through the open issues before opening a repeated one :)  Include as much context info as possible, also ideally the following things:    The inserted entity that may have caused the problem. E.g:  {\n    'id': 'MyEntityId',\n    'type': 'MyEntityType',\n    'attr1': 'blabla',\n    ...\n}    The payload of the subscription(s) that you created. See  this section \nof Orion documentation.    The logs of the QuantumLeap container.  The logs can be retrieved with the  docker logs command \nor  docker service logs \nif you deployed QL as a service. In the first case, you can discover the\ncontainer id with  docker ps -a . In the second case, use docker service ls  to find the service name.",
            "title": "Bug reporting"
        },
        {
            "location": "/user/contributing/",
            "text": "Contributions\n\n\nContributions are more than welcome in the form of pull requests.\n\n\nYou can either pick one of the \nopen issues\n\nto work on, or provide enhancements according to your own needs. In any case,\nwe suggest getting in touch beforehand to make sure the contribution will be\naligned with the current development status.\n\n\nTo contribute:\n\n\n\n\nFork the repository and clone the fork to your local development environment\n\n\nIdentify a modular contribution to the code (avoid too large contributions\n    to simplify review)\n\n\nCreate a branch in your repository where you tackle the \"modular\ncontributions\"\n\n\nFor multiple contributions tackling different functionalities, create\n   different branches\n\n\nFor all the new functionalities provide tests (see \nsetup_dev_env.sh\n\n   and \nrun.sh\n in the root to understand how tests can be run locally)\n\n\nWhen done, verify that all tests are passing\n\n\nIf so, create a pull request against our repository (we cannot review pull\n   requests with failing tests)\n\n\nWait for the review\n\n\nImplement required changes\n\n\nRepeat until approval\n\n\nDone :) You can delete the branch in your repository.\n\n\n\n\nDevelopment Setup\n\n\nThe development is mostly in \npython3\n for now, and really in the early stages\nso things will change for sure. For now, you can start with:\n\n\ngit clone https://github.com/smartsdk/ngsi-timeseries-api.git\ncd ngsi-timeseries-api\npython3 -m venv env\npip install -r requirements.txt\n\n# if you want to test everything locally, you'll need to...\nsource setup_dev_env.sh\n\n\n\npytest\n is used as the testing framework,\nbut since most of QL's functionality is integration of components, you'll find \ndocker-compose.yml\n files in the test folders to be run as a setup for tests.\nIf you see \n.travis.yml\n file you'll see how they are running today, but\nprobably at some point it's worth exploring \npytest-docker\n plugins.\n\n\nThe \nrequirements.txt\n still needs to be split between testing and production,\nthat's also why the docker image is massive for now.\n\n\nRepository Structure\n\n\nIn the current project tree structure you can find:\n\n\n\n\nngsi-timeseries-api\n\n\nclient\n: Holds a simple Orion Context Broker client to ease integration\ntesting. To be moved out of this repo.\n\n\ndoc\n: Holds documentation files.\n\n\ndocker\n: To hold docker-related files for the scope of the project.\n\n\nexperiments\n: Sandbox for quick manual tests to try some stuff and\nderive new test cases.\n\n\ngeocoding\n: Holds the code for interacting with OSM and doing\ngeo-related processing.\n\n\nreporter\n: Modules acting as the receiver of the notifications and API\nrequests. It \"parses/validates\" them before handling tasks to the\ntranslators.\n\n\nspecification\n: Holds the swagger-based \nngsi-tsdb\n API specification\nthat QL implements.\n\n\ntranslators\n: Specific translators for each time-series databases,\nresponsible for interacting with the lower-level database details.\n\n\nutils\n: Common shared stuff looking for a better place to live in.",
            "title": "Contributing"
        },
        {
            "location": "/user/contributing/#contributions",
            "text": "Contributions are more than welcome in the form of pull requests.  You can either pick one of the  open issues \nto work on, or provide enhancements according to your own needs. In any case,\nwe suggest getting in touch beforehand to make sure the contribution will be\naligned with the current development status.  To contribute:   Fork the repository and clone the fork to your local development environment  Identify a modular contribution to the code (avoid too large contributions\n    to simplify review)  Create a branch in your repository where you tackle the \"modular\ncontributions\"  For multiple contributions tackling different functionalities, create\n   different branches  For all the new functionalities provide tests (see  setup_dev_env.sh \n   and  run.sh  in the root to understand how tests can be run locally)  When done, verify that all tests are passing  If so, create a pull request against our repository (we cannot review pull\n   requests with failing tests)  Wait for the review  Implement required changes  Repeat until approval  Done :) You can delete the branch in your repository.",
            "title": "Contributions"
        },
        {
            "location": "/user/contributing/#development-setup",
            "text": "The development is mostly in  python3  for now, and really in the early stages\nso things will change for sure. For now, you can start with:  git clone https://github.com/smartsdk/ngsi-timeseries-api.git\ncd ngsi-timeseries-api\npython3 -m venv env\npip install -r requirements.txt\n\n# if you want to test everything locally, you'll need to...\nsource setup_dev_env.sh  pytest  is used as the testing framework,\nbut since most of QL's functionality is integration of components, you'll find  docker-compose.yml  files in the test folders to be run as a setup for tests.\nIf you see  .travis.yml  file you'll see how they are running today, but\nprobably at some point it's worth exploring  pytest-docker  plugins.  The  requirements.txt  still needs to be split between testing and production,\nthat's also why the docker image is massive for now.",
            "title": "Development Setup"
        },
        {
            "location": "/user/contributing/#repository-structure",
            "text": "In the current project tree structure you can find:   ngsi-timeseries-api  client : Holds a simple Orion Context Broker client to ease integration\ntesting. To be moved out of this repo.  doc : Holds documentation files.  docker : To hold docker-related files for the scope of the project.  experiments : Sandbox for quick manual tests to try some stuff and\nderive new test cases.  geocoding : Holds the code for interacting with OSM and doing\ngeo-related processing.  reporter : Modules acting as the receiver of the notifications and API\nrequests. It \"parses/validates\" them before handling tasks to the\ntranslators.  specification : Holds the swagger-based  ngsi-tsdb  API specification\nthat QL implements.  translators : Specific translators for each time-series databases,\nresponsible for interacting with the lower-level database details.  utils : Common shared stuff looking for a better place to live in.",
            "title": "Repository Structure"
        },
        {
            "location": "/admin/",
            "text": "Installing\n\n\nAt the moment, the only actively supported distribution of QuantumLeap is based\non Docker. You could build and install it from sources, but no guidance is\nprovided for such installation at the moment.\n\n\nIf you need to install Docker, refer to the \nDocker Installation\n.\nTo check it works, you should be able to successfully run...\n\n\ndocker --version\n\n\n\n\nYou might also need \ndocker-compose\n for\nsome cases. Checkout the \ninstall docs\n.\nTo check it works, you should be able to successfully run...\n\n\ndocker-compose --version\n\n\n\n\nThe QuantumLeap Docker Image is hosted at \nhttps://hub.docker.com/r/smartsdk/quantumleap/\n.\n\n\nNow, depending on your scenario, you have different deployment options. See\nfrom the sections below which fits yours.\n\n\nDeploy QuantumLeap on a single-host for local testing\n\n\nFollow these steps if you want to quickly deploy all the components of the\n\ntypical scenario\n at once, to start experimenting with\nQuantumLeap ASAP.\n\n\nImportant:\n Do not use this approach for production environments.\n\n\nDownload (or create locally) a copy of \nthis docker-compose.yml\n\nfile. Then start it up:\n\n\n# same path were you have placed the docker-compose-dev.yml\n$ docker stack deploy -c docker-compose-dev.yml ql\n\n\n\n\nNOTE:\n If you are using an old docker version, it might be the case that your\nlocal docker daemon is not running in the \nswarm mode\n and the above command\nfails. You can either update your docker installation (suggested), enable the\n\nswarm mode\n executing \ndocker swarm init\n or ultimately fall back to\ndeploying using \ndocker-compose\n\n(\ndocker-compose -f docker-compose-dev.yml up -d\n).\n\n\nAfter a while, check that all containers are running (up):\n\n\n$ docker service ls\nID                  NAME                MODE                REPLICAS            IMAGE                         PORTS\nzpkl93c67ix1        ql_crate            replicated          1/1                 crate:1.0.5                   *:4200->4200/tcp, *:4300->4300/tcp\ns3dkplowfvhy        ql_grafana          replicated          1/1                 grafana/grafana:latest        *:3000->3000/tcp\nafdrgwc4eo1r        ql_mongo            replicated          1/1                 mongo:3.2                     *:27017->27017/tcp\nl32fn6yft42q        ql_orion            replicated          1/1                 fiware/orion:1.13.0           *:1026->1026/tcp\ngcm1lszuj2k8        ql_quantumleap      replicated          1/1                 smartsdk/quantumleap:latest   *:8668->8668/tcp\nrrnd03qqb2il        ql_redis            replicated          1/1                 redis:latest                  *:6379->6379/tcp\n\n\n\n\nNow you're ready to use QuantumLeap as instructed in the \nUser Manual\n.\n\n\nWhen you are done experimenting, remember to teardown the stack.\n\n\n$ docker stack rm ql\n\n\n\n\nDeploy QuantumLeap in HA on a Docker Swarm cluster\n\n\nTo deploy QuantumLeap services in HA as a service on a Docker Swarm Cluster,\nyou can follow the instructions in \nthis repository\n.\n\n\nThere, you will find instructions on how to deploy in HA not only\n\nQuantumLeap\n but also all the complementary services that typically form\npart of the deployment scenario.\n\n\nDeploy QuantumLeap reusing external services instances\n\n\nIf you have already Orion running somewhere else and you just want to deploy\nQuantumLeap, you can proceed as explained in the previous sections, but before\ndeploying, remove from the docker-compose file the complete definition of\nthe \norion:\n and \nmongo:\n services. You will also need to remove the\nreferences to them in the \ndepends_on:\n section of the other services.\n\n\nSimilarly, if you don't want to use some of the complementary services, like\n\ngrafana\n, you can remove such services definition as well. Ultimately, the\nonly required services for a minimal functioning QL are \nquantumleap\n and the\ntime-series database (\ncrate\n in the common case).\n\n\nAlternatively, if you only need to run QuantumLeap to complete your setup, you\ncan simply run\n\n\ndocker run -d -p 8668:8668 -e \"CRATE_HOST=http://your_crate_location\" smartsdk/quantumleap\n\n\n\n\nThe environment variable \nCRATE_HOST\n will tell QuantumLeap where to reach\n\nCrate\n, so you need to provide a reachable hostname where Crate is running.\nBy default QL will append the port \n4200\n to the hostname. You can of course\nadd your required environment variables with \n-e\n. For more options see \ndocker run reference\n.",
            "title": "Introduction"
        },
        {
            "location": "/admin/#installing",
            "text": "At the moment, the only actively supported distribution of QuantumLeap is based\non Docker. You could build and install it from sources, but no guidance is\nprovided for such installation at the moment.  If you need to install Docker, refer to the  Docker Installation .\nTo check it works, you should be able to successfully run...  docker --version  You might also need  docker-compose  for\nsome cases. Checkout the  install docs .\nTo check it works, you should be able to successfully run...  docker-compose --version  The QuantumLeap Docker Image is hosted at  https://hub.docker.com/r/smartsdk/quantumleap/ .  Now, depending on your scenario, you have different deployment options. See\nfrom the sections below which fits yours.",
            "title": "Installing"
        },
        {
            "location": "/admin/#deploy-quantumleap-on-a-single-host-for-local-testing",
            "text": "Follow these steps if you want to quickly deploy all the components of the typical scenario  at once, to start experimenting with\nQuantumLeap ASAP.  Important:  Do not use this approach for production environments.  Download (or create locally) a copy of  this docker-compose.yml \nfile. Then start it up:  # same path were you have placed the docker-compose-dev.yml\n$ docker stack deploy -c docker-compose-dev.yml ql  NOTE:  If you are using an old docker version, it might be the case that your\nlocal docker daemon is not running in the  swarm mode  and the above command\nfails. You can either update your docker installation (suggested), enable the swarm mode  executing  docker swarm init  or ultimately fall back to\ndeploying using  docker-compose \n( docker-compose -f docker-compose-dev.yml up -d ).  After a while, check that all containers are running (up):  $ docker service ls\nID                  NAME                MODE                REPLICAS            IMAGE                         PORTS\nzpkl93c67ix1        ql_crate            replicated          1/1                 crate:1.0.5                   *:4200->4200/tcp, *:4300->4300/tcp\ns3dkplowfvhy        ql_grafana          replicated          1/1                 grafana/grafana:latest        *:3000->3000/tcp\nafdrgwc4eo1r        ql_mongo            replicated          1/1                 mongo:3.2                     *:27017->27017/tcp\nl32fn6yft42q        ql_orion            replicated          1/1                 fiware/orion:1.13.0           *:1026->1026/tcp\ngcm1lszuj2k8        ql_quantumleap      replicated          1/1                 smartsdk/quantumleap:latest   *:8668->8668/tcp\nrrnd03qqb2il        ql_redis            replicated          1/1                 redis:latest                  *:6379->6379/tcp  Now you're ready to use QuantumLeap as instructed in the  User Manual .  When you are done experimenting, remember to teardown the stack.  $ docker stack rm ql",
            "title": "Deploy QuantumLeap on a single-host for local testing"
        },
        {
            "location": "/admin/#deploy-quantumleap-in-ha-on-a-docker-swarm-cluster",
            "text": "To deploy QuantumLeap services in HA as a service on a Docker Swarm Cluster,\nyou can follow the instructions in  this repository .  There, you will find instructions on how to deploy in HA not only QuantumLeap  but also all the complementary services that typically form\npart of the deployment scenario.",
            "title": "Deploy QuantumLeap in HA on a Docker Swarm cluster"
        },
        {
            "location": "/admin/#deploy-quantumleap-reusing-external-services-instances",
            "text": "If you have already Orion running somewhere else and you just want to deploy\nQuantumLeap, you can proceed as explained in the previous sections, but before\ndeploying, remove from the docker-compose file the complete definition of\nthe  orion:  and  mongo:  services. You will also need to remove the\nreferences to them in the  depends_on:  section of the other services.  Similarly, if you don't want to use some of the complementary services, like grafana , you can remove such services definition as well. Ultimately, the\nonly required services for a minimal functioning QL are  quantumleap  and the\ntime-series database ( crate  in the common case).  Alternatively, if you only need to run QuantumLeap to complete your setup, you\ncan simply run  docker run -d -p 8668:8668 -e \"CRATE_HOST=http://your_crate_location\" smartsdk/quantumleap  The environment variable  CRATE_HOST  will tell QuantumLeap where to reach Crate , so you need to provide a reachable hostname where Crate is running.\nBy default QL will append the port  4200  to the hostname. You can of course\nadd your required environment variables with  -e . For more options see  docker run reference .",
            "title": "Deploy QuantumLeap reusing external services instances"
        },
        {
            "location": "/admin/ports/",
            "text": "Used Ports\n\n\nThe table below summarises the default ports for each of the services typically\nused with QuantumLeap. So, if you run them behind firewalls, remember to\ninclude the corresponding rules.\n\n\n\n\n\n\n\n\nProtocol\n\n\nPort\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nTCP\n\n\n1026\n\n\nOrion CB\n\n\n\n\n\n\nTCP\n\n\n8668\n\n\nQuantumLeap's API\n\n\n\n\n\n\nTCP\n\n\n3000\n\n\nGrafana\n\n\n\n\n\n\n\n\nJust FYI, the following ones should not be typically exposed to the outside but\nare used within the cluster.\n\n\n\n\n\n\n\n\nProtocol\n\n\nPort\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nTCP\n\n\n27017\n\n\nMongo database\n\n\n\n\n\n\nTCP\n\n\n4200\n\n\nCrateDB Admin UI\n\n\n\n\n\n\nTCP\n\n\n4300\n\n\nCrateDB Transport Protocol\n\n\n\n\n\n\nTCP\n\n\n6379\n\n\nRedis cache (used by geocoding)\n\n\n\n\n\n\n\n\nFor more info on ports numbers, you can always inspect the ports being exposed\nin the \ndocker-compose.yml\n files of this repo.",
            "title": "Ports"
        },
        {
            "location": "/admin/ports/#used-ports",
            "text": "The table below summarises the default ports for each of the services typically\nused with QuantumLeap. So, if you run them behind firewalls, remember to\ninclude the corresponding rules.     Protocol  Port  Description      TCP  1026  Orion CB    TCP  8668  QuantumLeap's API    TCP  3000  Grafana     Just FYI, the following ones should not be typically exposed to the outside but\nare used within the cluster.     Protocol  Port  Description      TCP  27017  Mongo database    TCP  4200  CrateDB Admin UI    TCP  4300  CrateDB Transport Protocol    TCP  6379  Redis cache (used by geocoding)     For more info on ports numbers, you can always inspect the ports being exposed\nin the  docker-compose.yml  files of this repo.",
            "title": "Used Ports"
        },
        {
            "location": "/admin/crate/",
            "text": "Crate\n\n\nCrate\n is QuantumLeap's default backend where NGSI data\nwill be persisted. In addition to using QL's API, if you want to extend QL, you\ncan also interact directly with Crate to query all the data QuantumLeap has\nstored from the received notifications.\n\n\nIf you followed the \nInstallation Guide\n, you have a ready-to-use\nCrate instance running in a Docker container. The easiest way to interact with\nit is using its admin interface, as documented \nhere\n.\nAlternatively, you can use its \nHTTP api\n,\nor any of its \nsupported clients\n.\n\n\nYou can learn more about Crate by reading \nthe docs\n.",
            "title": "Crate"
        },
        {
            "location": "/admin/crate/#crate",
            "text": "Crate  is QuantumLeap's default backend where NGSI data\nwill be persisted. In addition to using QL's API, if you want to extend QL, you\ncan also interact directly with Crate to query all the data QuantumLeap has\nstored from the received notifications.  If you followed the  Installation Guide , you have a ready-to-use\nCrate instance running in a Docker container. The easiest way to interact with\nit is using its admin interface, as documented  here .\nAlternatively, you can use its  HTTP api ,\nor any of its  supported clients .  You can learn more about Crate by reading  the docs .",
            "title": "Crate"
        },
        {
            "location": "/admin/grafana/",
            "text": "Grafana\n\n\nGrafana\n is a powerful visualisation tool that we\ncan use to display graphics of the persisted data.\n\n\nIn order to read data from a \nCrate\n database, grafana leverages on\nthe \nGrafana Datasource Plugin for CrateDB\n.\n\n\nIf you followed the \nInstallation Guide\n, you have already Grafana\nrunning in a Docker container, with the crate-datasource plugin already\ninstalled.\n\n\nFor now, crate data sources are restricted to a single table, and Quantum leap\ncreates one table per entity type; hence, you'll have to create one data source\nper entity type. If this is a problem/limitation for you, \nopen an issue in\nquantumleap's repo\n\nand we can see how to work this out.\n\n\nConfiguring the DataSource\n\n\nExplore your deployed grafana instance (e.g http://localhost:3000). If you\ndidn't change the defaults credentials, use \nadmin\n as both user and password.\n\n\nGo to \nAdd data source\n and fill in the required fields, with the following\nobservations:\n\n\n\n\nName\n: This is the name you want for the Datasource. We recommend naming\nit after the entity type (i.e, the table you will connect to).\n\n\nType\n: Use \nCrate\n. If you don't see \nCrate\n as an option, check your\ninstallation of the datasource plugin in the container.\n\n\nUrl\n: The full url where cratedb was deployed.\n\n\nAccess\n: Use \ndirect\n if you're deploying everything locally. If you are\ndeploying crate behind a proxy (as in the case of \nHA deployment\n),\nchoose the \nproxy\n option instead.\n\n\nSchema\n: The schema where the table is defined. By default, crate uses\n\ndoc\n schema, but if you are using multi-tenancy headers, the schema will be\ndefined by the tenant of the entity type. More info in the\n\nMulti-tenancy section\n.\n\n\nTable\n: The name of the table of the entity. See the \nData Retrieval\n section to know how table names are\ndefined.\n\n\nTime column\n: The name of the column used as time index. By default, it is \ntime_index\n, as explained in the \nTime Index\n\n section.\n\n\n\n\nThe following image shows an example of the datasource configuration for an\nentity type called \nyourentity\n\n\n\n\nUsing the DataSource in your Graph\n\n\nHaving your datasource setup, you can start using it in the different\nvisualisation widgets.\n\n\nThe following is an example of a Graph using a Crate datasource. Note the\nselection of the datasource (called CrateDB in this case), as well as the\nspecification of the table in the \nfrom\n field. Note that the table is\nreferenced as \nschema.tablename\n (e.g: \ndoc.etairqualityobserved\n)",
            "title": "Grafana"
        },
        {
            "location": "/admin/grafana/#grafana",
            "text": "Grafana  is a powerful visualisation tool that we\ncan use to display graphics of the persisted data.  In order to read data from a  Crate  database, grafana leverages on\nthe  Grafana Datasource Plugin for CrateDB .  If you followed the  Installation Guide , you have already Grafana\nrunning in a Docker container, with the crate-datasource plugin already\ninstalled.  For now, crate data sources are restricted to a single table, and Quantum leap\ncreates one table per entity type; hence, you'll have to create one data source\nper entity type. If this is a problem/limitation for you,  open an issue in\nquantumleap's repo \nand we can see how to work this out.",
            "title": "Grafana"
        },
        {
            "location": "/admin/grafana/#configuring-the-datasource",
            "text": "Explore your deployed grafana instance (e.g http://localhost:3000). If you\ndidn't change the defaults credentials, use  admin  as both user and password.  Go to  Add data source  and fill in the required fields, with the following\nobservations:   Name : This is the name you want for the Datasource. We recommend naming\nit after the entity type (i.e, the table you will connect to).  Type : Use  Crate . If you don't see  Crate  as an option, check your\ninstallation of the datasource plugin in the container.  Url : The full url where cratedb was deployed.  Access : Use  direct  if you're deploying everything locally. If you are\ndeploying crate behind a proxy (as in the case of  HA deployment ),\nchoose the  proxy  option instead.  Schema : The schema where the table is defined. By default, crate uses doc  schema, but if you are using multi-tenancy headers, the schema will be\ndefined by the tenant of the entity type. More info in the Multi-tenancy section .  Table : The name of the table of the entity. See the  Data Retrieval  section to know how table names are\ndefined.  Time column : The name of the column used as time index. By default, it is  time_index , as explained in the  Time Index \n section.   The following image shows an example of the datasource configuration for an\nentity type called  yourentity",
            "title": "Configuring the DataSource"
        },
        {
            "location": "/admin/grafana/#using-the-datasource-in-your-graph",
            "text": "Having your datasource setup, you can start using it in the different\nvisualisation widgets.  The following is an example of a Graph using a Crate datasource. Note the\nselection of the datasource (called CrateDB in this case), as well as the\nspecification of the table in the  from  field. Note that the table is\nreferenced as  schema.tablename  (e.g:  doc.etairqualityobserved )",
            "title": "Using the DataSource in your Graph"
        }
    ]
}